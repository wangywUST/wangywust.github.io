
@inproceedings{wang_mixup_2021,
	address = {Ljubljana Slovenia},
	title = {Mixup for {Node} and {Graph} {Classification}},
	isbn = {978-1-4503-8312-7},
	url = {https://dl.acm.org/doi/10.1145/3442381.3449796},
	doi = {10.1145/3442381.3449796},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	month = apr,
	year = {2021},
	pages = {3663--3674},
	file = {Available Version (via Google Scholar):C\:\\Users\\wangy\\Zotero\\storage\\VWMUR2YZ\\Wang 等 - 2021 - Mixup for Node and Graph Classification.pdf:application/pdf},
}

@inproceedings{wang_nodeaug_2020,
	address = {Virtual Event CA USA},
	title = {{NodeAug}: {Semi}-{Supervised} {Node} {Classification} with {Data} {Augmentation}},
	isbn = {978-1-4503-7998-4},
	shorttitle = {{NodeAug}},
	url = {https://dl.acm.org/doi/10.1145/3394486.3403063},
	doi = {10.1145/3394486.3403063},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Liu, Juncheng and Hooi, Bryan},
	month = aug,
	year = {2020},
	pages = {207--217},
}

@incollection{vedaldi_learning_2020,
	address = {Cham},
	title = {Learning {Progressive} {Joint} {Propagation} for {Human} {Motion} {Prediction}},
	volume = {12352},
	isbn = {978-3-030-58570-9 978-3-030-58571-6},
	url = {https://link.springer.com/10.1007/978-3-030-58571-6_14},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Computer {Vision} – {ECCV} 2020},
	publisher = {Springer International Publishing},
	author = {Cai, Yujun and Huang, Lin and Wang, Yiwei and Cham, Tat-Jen and Cai, Jianfei and Yuan, Junsong and Liu, Jun and Yang, Xu and Zhu, Yiheng and Shen, Xiaohui and Liu, Ding and Liu, Jing and Thalmann, Nadia Magnenat},
	editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
	year = {2020},
	doi = {10.1007/978-3-030-58571-6_14},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {226--242},
}

@inproceedings{liang_fine-grained_2021,
	address = {Ljubljana Slovenia},
	title = {Fine-{Grained} {Urban} {Flow} {Prediction}},
	isbn = {978-1-4503-8312-7},
	url = {https://dl.acm.org/doi/10.1145/3442381.3449792},
	doi = {10.1145/3442381.3449792},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Liang, Yuxuan and Ouyang, Kun and Sun, Junkai and Wang, Yiwei and Zhang, Junbo and Zheng, Yu and Rosenblum, David and Zimmermann, Roger},
	month = apr,
	year = {2021},
	pages = {1833--1845},
}

@inproceedings{liang_airformer_2023,
	title = {Airformer: {Predicting} nationwide air quality in china with transformers},
	volume = {37},
	shorttitle = {Airformer},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26676},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Liang, Yuxuan and Xia, Yutong and Ke, Songyu and Wang, Yiwei and Wen, Qingsong and Zhang, Junbo and Zheng, Yu and Zimmermann, Roger},
	year = {2023},
	note = {Issue: 12},
	pages = {14329--14337},
}

@misc{wang_graphcrop_2020,
	title = {{GraphCrop}: {Subgraph} {Cropping} for {Graph} {Classification}},
	shorttitle = {{GraphCrop}},
	url = {http://arxiv.org/abs/2009.10564},
	doi = {10.48550/arXiv.2009.10564},
	abstract = {We present a new method to regularize graph neural networks (GNNs) for better generalization in graph classification. Observing that the omission of sub-structures does not necessarily change the class label of the whole graph, we develop the {\textbackslash}textbf\{GraphCrop\} (Subgraph Cropping) data augmentation method to simulate the real-world noise of sub-structure omission. In principle, GraphCrop utilizes a node-centric strategy to crop a contiguous subgraph from the original graph while maintaining its connectivity. By preserving the valid structure contexts for graph classification, we encourage GNNs to understand the content of graph structures in a global sense, rather than rely on a few key nodes or edges, which may not always be present. GraphCrop is parameter learning free and easy to implement within existing GNN-based graph classifiers. Qualitatively, GraphCrop expands the existing training set by generating novel and informative augmented graphs, which retain the original graph labels in most cases. Quantitatively, GraphCrop yields significant and consistent gains on multiple standard datasets, and thus enhances the popular GNNs to outperform the baseline methods.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	month = sep,
	year = {2020},
	note = {arXiv:2009.10564 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Social and Information Networks},
}

@inproceedings{cai_unified_2021,
	title = {A unified 3d human motion synthesis model via conditional variational auto-encoder},
	url = {http://openaccess.thecvf.com/content/ICCV2021/html/Cai_A_Unified_3D_Human_Motion_Synthesis_Model_via_Conditional_Variational_ICCV_2021_paper.html},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision}},
	author = {Cai, Yujun and Wang, Yiwei and Zhu, Yiheng and Cham, Tat-Jen and Cai, Jianfei and Yuan, Junsong and Liu, Jun and Zheng, Chuanxia and Yan, Sijie and Ding, Henghui},
	year = {2021},
	pages = {11645--11655},
}

@article{wang_adaptive_2021,
	title = {Adaptive data augmentation on temporal graphs},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/0b0b0994d12ad343511adfbfc364256e-Abstract.html},
	urldate = {2024-12-29},
	journal = {Advances in Neural Information Processing Systems},
	author = {Wang, Yiwei and Cai, Yujun and Liang, Yuxuan and Ding, Henghui and Wang, Changhu and Bhatia, Siddharth and Hooi, Bryan},
	year = {2021},
	pages = {1440--1452},
}

@inproceedings{wang_curgraph_2021,
	address = {Ljubljana Slovenia},
	title = {{CurGraph}: {Curriculum} {Learning} for {Graph} {Classification}},
	isbn = {978-1-4503-8312-7},
	shorttitle = {{CurGraph}},
	url = {https://dl.acm.org/doi/10.1145/3442381.3450025},
	doi = {10.1145/3442381.3450025},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	month = apr,
	year = {2021},
	pages = {1238--1248},
}

@article{liu_eignn_2021,
	title = {Eignn: {Efficient} infinite-depth graph neural networks},
	volume = {34},
	shorttitle = {Eignn},
	url = {https://proceedings.neurips.cc/paper/2021/hash/9bd5ee6fe55aaeb673025dbcb8f939c1-Abstract.html},
	urldate = {2024-12-29},
	journal = {Advances in Neural Information Processing Systems},
	author = {Liu, Juncheng and Kawaguchi, Kenji and Hooi, Bryan and Wang, Yiwei and Xiao, Xiaokui},
	year = {2021},
	pages = {18762--18773},
}

@article{zhao_optimization_2019,
	title = {Optimization algorithms for graph {Laplacian} estimation via {ADMM} and {MM}},
	volume = {67},
	url = {https://ieeexplore.ieee.org/abstract/document/8747497/},
	number = {16},
	urldate = {2024-12-29},
	journal = {IEEE Transactions on Signal Processing},
	author = {Zhao, Licheng and Wang, Yiwei and Kumar, Sandeep and Palomar, Daniel P.},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {4231--4244},
}

@incollection{hutter_revisiting_2021,
	address = {Cham},
	title = {Revisiting {Convolutional} {Neural} {Networks} for {Citywide} {Crowd} {Flow} {Analytics}},
	volume = {12457},
	isbn = {978-3-030-67657-5 978-3-030-67658-2},
	url = {https://link.springer.com/10.1007/978-3-030-67658-2_33},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Liang, Yuxuan and Ouyang, Kun and Wang, Yiwei and Liu, Ye and Zhang, Junbo and Zheng, Yu and Rosenblum, David S.},
	editor = {Hutter, Frank and Kersting, Kristian and Lijffijt, Jefrey and Valera, Isabel},
	year = {2021},
	doi = {10.1007/978-3-030-67658-2_33},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {578--594},
}

@inproceedings{liang_modeling_2021,
	title = {Modeling {Trajectories} with {Neural} {Ordinary} {Differential} {Equations}.},
	url = {https://www.ijcai.org/proceedings/2021/0207.pdf},
	urldate = {2024-12-29},
	booktitle = {{IJCAI}},
	author = {Liang, Yuxuan and Ouyang, Kun and Yan, Hanshu and Wang, Yiwei and Tong, Zekun and Zimmermann, Roger},
	year = {2021},
	pages = {1498--1504},
}

@misc{wang_should_2022,
	title = {Should {We} {Rely} on {Entity} {Mentions} for {Relation} {Extraction}? {Debiasing} {Relation} {Extraction} with {Counterfactual} {Analysis}},
	shorttitle = {Should {We} {Rely} on {Entity} {Mentions} for {Relation} {Extraction}?},
	url = {http://arxiv.org/abs/2205.03784},
	doi = {10.48550/arXiv.2205.03784},
	abstract = {Recent literature focuses on utilizing the entity information in the sentence-level relation extraction (RE), but this risks leaking superficial and spurious clues of relations. As a result, RE still suffers from unintended entity bias, i.e., the spurious correlation between entity mentions (names) and relations. Entity bias can mislead the RE models to extract the relations that do not exist in the text. To combat this issue, some previous work masks the entity mentions to prevent the RE models from overfitting entity mentions. However, this strategy degrades the RE performance because it loses the semantic information of entities. In this paper, we propose the CORE (Counterfactual Analysis based Relation Extraction) debiasing method that guides the RE models to focus on the main effects of textual context without losing the entity information. We first construct a causal graph for RE, which models the dependencies between variables in RE models. Then, we propose to conduct counterfactual analysis on our causal graph to distill and mitigate the entity bias, that captures the causal effects of specific entity mentions in each instance. Note that our CORE method is model-agnostic to debias existing RE systems during inference without changing their training processes. Extensive experimental results demonstrate that our CORE yields significant gains on both effectiveness and generalization for RE. The source code is provided at: https://github.com/vanoracai/CoRE.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Chen, Muhao and Zhou, Wenxuan and Cai, Yujun and Liang, Yuxuan and Liu, Dayiheng and Yang, Baosong and Liu, Juncheng and Hooi, Bryan},
	month = may,
	year = {2022},
	note = {arXiv:2205.03784 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: NAACL 2022},
}

@misc{wang_causal_2023,
	title = {A {Causal} {View} of {Entity} {Bias} in ({Large}) {Language} {Models}},
	url = {http://arxiv.org/abs/2305.14695},
	doi = {10.48550/arXiv.2305.14695},
	abstract = {Entity bias widely affects pretrained (large) language models, causing them to rely on (biased) parametric knowledge to make unfaithful predictions. Although causality-inspired methods have shown great potential to mitigate entity bias, it is hard to precisely estimate the parameters of underlying causal models in practice. The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate. Building upon this SCM, we propose causal intervention techniques to mitigate entity bias for both white-box and black-box settings. The proposed causal intervention perturbs the original entity with neighboring entities. This intervention reduces specific biasing information pertaining to the original entity while still preserving sufficient semantic information from similar entities. Under the white-box setting, our training-time intervention improves OOD performance of PLMs on relation extraction (RE) and machine reading comprehension (MRC) by 5.7 points and by 9.1 points, respectively. Under the black-box setting, our in-context intervention effectively reduces the entity-based knowledge conflicts of GPT-3.5, achieving up to 20.5 points of improvement of exact match accuracy on MRC and up to 17.6 points of reduction in memorization ratio on RE. Our code is available at https://github.com/luka-group/Causal-View-of-Entity-Bias.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Fei and Mo, Wenjie and Wang, Yiwei and Zhou, Wenxuan and Chen, Muhao},
	month = oct,
	year = {2023},
	note = {arXiv:2305.14695 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Findings of EMNLP 2023},
}

@misc{wang_primacy_2024,
	title = {Primacy {Effect} of {ChatGPT}},
	url = {http://arxiv.org/abs/2310.13206},
	doi = {10.48550/arXiv.2310.13206},
	abstract = {Instruction-tuned large language models (LLMs), such as ChatGPT, have led to promising zero-shot performance in discriminative natural language understanding (NLU) tasks. This involves querying the LLM using a prompt containing the question, and the candidate labels to choose from. The question-answering capabilities of ChatGPT arise from its pre-training on large amounts of human-written text, as well as its subsequent fine-tuning on human preferences, which motivates us to ask: Does ChatGPT also inherits humans' cognitive biases? In this paper, we study the primacy effect of ChatGPT: the tendency of selecting the labels at earlier positions as the answer. We have two main findings: i) ChatGPT's decision is sensitive to the order of labels in the prompt; ii) ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer. We hope that our experiments and analyses provide additional insights into building more reliable ChatGPT-based solutions. We release the source code at https://github.com/wangywUST/PrimacyEffectGPT.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Cai, Yujun and Chen, Muhao and Liang, Yuxuan and Hooi, Bryan},
	month = may,
	year = {2024},
	note = {arXiv:2310.13206 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2023 short paper},
}

@article{liang_mixed-order_2022,
	title = {Mixed-order relation-aware recurrent neural networks for spatio-temporal forecasting},
	volume = {35},
	url = {https://ieeexplore.ieee.org/abstract/document/9956738/},
	number = {9},
	urldate = {2024-12-29},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Liang, Yuxuan and Ouyang, Kun and Wang, Yiwei and Pan, Zheyi and Yin, Yifang and Chen, Hongyang and Zhang, Junbo and Zheng, Yu and Rosenblum, David S. and Zimmermann, Roger},
	year = {2022},
	note = {Publisher: IEEE},
	pages = {9254--9268},
}

@misc{wang_deepedit_2024,
	title = {{DeepEdit}: {Knowledge} {Editing} as {Decoding} with {Constraints}},
	shorttitle = {{DeepEdit}},
	url = {http://arxiv.org/abs/2401.10471},
	doi = {10.48550/arXiv.2401.10471},
	abstract = {How to edit the knowledge in multi-step reasoning has become the major challenge in the knowledge editing (KE) of large language models (LLMs). The difficulty arises because the hallucinations of LLMs during multi-step reasoning often lead to incorrect use of new knowledge and incorrect answers. To address this issue, we design decoding constraints to "regulate" LLMs' reasoning, enhancing logical coherence when incorporating new knowledge. We propose a new KE framework: DEEPEDIT (Depth-first Search-based Constrained Decoding for Knowledge Editing), which enhances LLMs's ability to generate coherent reasoning chains with new knowledge through depth-first search. Our search selects the most important knowledge that satisfies our constraints as the reasoning step to efficiently increase the reasoning depth. In addition to DEEPEDIT, we propose two new KE benchmarks: MQUAKE-2002 and MQUAKE-HARD, which provide more precise and challenging assessments of KE approaches. Qualitatively, DEEPEDIT enables LLMs to produce succinct and coherent reasoning chains involving new knowledge. Quantitatively, it yields significant improvements on multiple KE benchmarks.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Chen, Muhao and Peng, Nanyun and Chang, Kai-Wei},
	month = nov,
	year = {2024},
	note = {arXiv:2401.10471 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wang_provably_2020,
	title = {Provably robust node classification via low-pass message passing},
	url = {https://ieeexplore.ieee.org/abstract/document/9338297/},
	urldate = {2024-12-29},
	booktitle = {2020 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Wang, Yiwei and Liu, Shenghua and Yoon, Minji and Lamba, Hemank and Wang, Wei and Faloutsos, Christos and Hooi, Bryan},
	year = {2020},
	pages = {621--630},
}

@misc{bi_decoding_2024,
	title = {Decoding by {Contrasting} {Knowledge}: {Enhancing} {LLMs}' {Confidence} on {Edited} {Facts}},
	shorttitle = {Decoding by {Contrasting} {Knowledge}},
	url = {http://arxiv.org/abs/2405.11613},
	doi = {10.48550/arXiv.2405.11613},
	abstract = {The knowledge within large language models (LLMs) may become outdated quickly. While in-context editing (ICE) is currently the most effective method for knowledge editing (KE), it is constrained by the black-box modeling of LLMs and thus lacks interpretability. Our work aims to elucidate the superior performance of ICE on the KE by analyzing the impacts of in-context new knowledge on token-wise distributions. We observe that despite a significant boost in logits of the new knowledge, the performance of is still hindered by stubborn knowledge. Stubborn knowledge refers to as facts that have gained excessive confidence during pretraining, making it hard to edit effectively. To address this issue and further enhance the performance of ICE, we propose a novel approach termed \${\textbackslash}textbf\{De\}\$coding by \${\textbackslash}textbf\{C\}\$ontrasting \${\textbackslash}textbf\{K\}\$nowledge (DeCK). DeCK derives the distribution of the next token by contrasting the logits obtained from the newly edited knowledge guided by ICE with those from the unedited parametric knowledge. Our experiments consistently demonstrate that DeCK enhances the confidence of LLMs in edited facts. For instance, it improves the performance of LLaMA3-8B-instruct on MQuAKE by up to 219\%, demonstrating its capability to strengthen ICE in the editing of stubborn knowledge. Our work paves the way to develop the both effective and accountable KE methods for LLMs. (The source code is available at: https://deck-llm.meirtz.com)},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Bi, Baolong and Liu, Shenghua and Mei, Lingrui and Wang, Yiwei and Ji, Pengliang and Cheng, Xueqi},
	month = may,
	year = {2024},
	note = {arXiv:2405.11613 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{wang_detecting_2020,
	title = {Detecting implementation bugs in graph convolutional network based node classifiers},
	url = {https://ieeexplore.ieee.org/abstract/document/9251083/},
	urldate = {2024-12-29},
	booktitle = {2020 {IEEE} 31st {International} {Symposium} on {Software} {Reliability} {Engineering} ({ISSRE})},
	publisher = {IEEE},
	author = {Wang, Yiwei and Wang, Wei and Ca, Yujun and Hooi, Bryan and Ooi, Beng Chin},
	year = {2020},
	pages = {313--324},
}

@misc{liu_dangling-aware_2022,
	title = {Dangling-{Aware} {Entity} {Alignment} with {Mixed} {High}-{Order} {Proximities}},
	url = {http://arxiv.org/abs/2205.02406},
	doi = {10.48550/arXiv.2205.02406},
	abstract = {We study dangling-aware entity alignment in knowledge graphs (KGs), which is an underexplored but important problem. As different KGs are naturally constructed by different sets of entities, a KG commonly contains some dangling entities that cannot find counterparts in other KGs. Therefore, dangling-aware entity alignment is more realistic than the conventional entity alignment where prior studies simply ignore dangling entities. We propose a framework using mixed high-order proximities on dangling-aware entity alignment. Our framework utilizes both the local high-order proximity in a nearest neighbor subgraph and the global high-order proximity in an embedding space for both dangling detection and entity alignment. Extensive experiments with two evaluation settings shows that our framework more precisely detects dangling entities, and better aligns matchable entities. Further investigations demonstrate that our framework can mitigate the hubness problem on dangling-aware entity alignment.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Liu, Juncheng and Sun, Zequn and Hooi, Bryan and Wang, Yiwei and Liu, Dayiheng and Yang, Baosong and Xiao, Xiaokui and Chen, Muhao},
	month = may,
	year = {2022},
	note = {arXiv:2205.02406 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: NAACL 2022 (Findings)},
}

@misc{wang_time-aware_2021,
	title = {Time-{Aware} {Neighbor} {Sampling} for {Temporal} {Graph} {Networks}},
	url = {http://arxiv.org/abs/2112.09845},
	doi = {10.48550/arXiv.2112.09845},
	abstract = {We present a new neighbor sampling method on temporal graphs. In a temporal graph, predicting different nodes' time-varying properties can require the receptive neighborhood of various temporal scales. In this work, we propose the TNS (Time-aware Neighbor Sampling) method: TNS learns from temporal information to provide an adaptive receptive neighborhood for every node at any time. Learning how to sample neighbors is non-trivial, since the neighbor indices in time order are discrete and not differentiable. To address this challenge, we transform neighbor indices from discrete values to continuous ones by interpolating the neighbors' messages. TNS can be flexibly incorporated into popular temporal graph networks to improve their effectiveness without increasing their time complexity. TNS can be trained in an end-to-end manner. It needs no extra supervision and is automatically and implicitly guided to sample the neighbors that are most beneficial for prediction. Empirical results on multiple standard datasets show that TNS yields significant gains on edge prediction and node classification.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Cai, Yujun and Liang, Yuxuan and Ding, Henghui and Wang, Changhu and Hooi, Bryan},
	month = dec,
	year = {2021},
	note = {arXiv:2112.09845 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases, Computer Science - Social and Information Networks},
}

@article{liu_active_2020,
	title = {Active learning for node classification: {The} additional learning ability from unlabelled nodes},
	shorttitle = {Active learning for node classification},
	url = {https://scholar.google.com/scholar?cluster=2044598733319114315&hl=en&oi=scholarr},
	urldate = {2024-12-29},
	journal = {arXiv preprint arXiv:2012.07065},
	author = {Liu, Juncheng and Wang, Yiwei and Hooi, Bryan and Yang, Renchi and Xiao, Xiaokui},
	year = {2020},
}

@inproceedings{wang_graph_2023,
	address = {Singapore Singapore},
	title = {Graph {Explicit} {Neural} {Networks}: {Explicitly} {Encoding} {Graphs} for {Efficient} and {Accurate} {Inference}},
	isbn = {978-1-4503-9407-9},
	shorttitle = {Graph {Explicit} {Neural} {Networks}},
	url = {https://dl.acm.org/doi/10.1145/3539597.3570388},
	doi = {10.1145/3539597.3570388},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {Sixteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Wang, Yiwei and Hooi, Bryan and Liu, Yozen and Shah, Neil},
	month = feb,
	year = {2023},
	pages = {348--356},
}

@incollection{amini_lscale_2023,
	address = {Cham},
	title = {{LSCALE}: {Latent} {Space} {Clustering}-{Based} {Active} {Learning} for {Node} {Classification}},
	volume = {13713},
	isbn = {978-3-031-26386-6 978-3-031-26387-3},
	shorttitle = {{LSCALE}},
	url = {https://link.springer.com/10.1007/978-3-031-26387-3_4},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Liu, Juncheng and Wang, Yiwei and Hooi, Bryan and Yang, Renchi and Xiao, Xiaokui},
	editor = {Amini, Massih-Reza and Canu, Stéphane and Fischer, Asja and Guns, Tias and Kralj Novak, Petra and Tsoumakas, Grigorios},
	year = {2023},
	doi = {10.1007/978-3-031-26387-3_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {55--70},
}

@inproceedings{wang_flashlight_2022,
	title = {Flashlight: {Scalable} link prediction with effective decoders},
	shorttitle = {Flashlight},
	url = {https://proceedings.mlr.press/v198/wang22a.html},
	urldate = {2024-12-29},
	booktitle = {Learning on {Graphs} {Conference}},
	publisher = {PMLR},
	author = {Wang, Yiwei and Hooi, Bryan and Liu, Yozen and Zhao, Tong and Guo, Zhichun and Shah, Neil},
	year = {2022},
	pages = {14--1},
}

@misc{wang_graphcache_2022,
	title = {{GRAPHCACHE}: {Message} {Passing} as {Caching} for {Sentence}-{Level} {Relation} {Extraction}},
	shorttitle = {{GRAPHCACHE}},
	url = {http://arxiv.org/abs/2205.03786},
	doi = {10.48550/arXiv.2205.03786},
	abstract = {Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that propagates the features across sentences to learn better representations for RE. GRAPHCACHE aggregates the features from sentences in the whole dataset to learn global representations of properties, and use them to augment the local features within individual sentences. The global property features act as dataset-level prior knowledge for RE, and a complement to the sentence-level features. Inspired by the classical caching technique in computer systems, we develop GRAPHCACHE to update the property representations in an online manner. Overall, GRAPHCACHE yields significant effectiveness gains on RE and enables efficient message passing across all sentences in the dataset.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Chen, Muhao and Zhou, Wenxuan and Cai, Yujun and Liang, Yuxuan and Hooi, Bryan},
	month = may,
	year = {2022},
	note = {arXiv:2205.03786 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	annote = {Comment: NAACL 2022 (Findings)},
}

@misc{wang_how_2024,
	title = {How {Fragile} is {Relation} {Extraction} under {Entity} {Replacements}?},
	url = {http://arxiv.org/abs/2305.13551},
	doi = {10.48550/arXiv.2305.13551},
	abstract = {Relation extraction (RE) aims to extract the relations between entity names from the textual context. In principle, textual context determines the ground-truth relation and the RE models should be able to correctly identify the relations reflected by the textual context. However, existing work has found that the RE models memorize the entity name patterns to make RE predictions while ignoring the textual context. This motivates us to raise the question: ``are RE models robust to the entity replacements?'' In this work, we operate the random and type-constrained entity replacements over the RE instances in TACRED and evaluate the state-of-the-art RE models under the entity replacements. We observe the 30{\textbackslash}\% - 50{\textbackslash}\% F1 score drops on the state-of-the-art RE models under entity replacements. These results suggest that we need more efforts to develop effective RE models robust to entity replacements. We release the source code at https://github.com/wangywUST/RobustRE.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Hooi, Bryan and Wang, Fei and Cai, Yujun and Liang, Yuxuan and Zhou, Wenxuan and Tang, Jing and Duan, Manjuan and Chen, Muhao},
	month = may,
	year = {2024},
	note = {arXiv:2305.13551 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{liu_scalable_2024,
	title = {Scalable and {Effective} {Implicit} {Graph} {Neural} {Networks} on {Large} {Graphs}},
	url = {https://openreview.net/forum?id=QcMdPYBwTu},
	urldate = {2024-12-29},
	booktitle = {The {Twelfth} {International} {Conference} on {Learning} {Representations}},
	author = {Liu, Juncheng and Hooi, Bryan and Kawaguchi, Kenji and Wang, Yiwei and Dong, Chaosheng and Xiao, Xiaokui},
	year = {2024},
}

@incollection{hutter_progressive_2021,
	address = {Cham},
	title = {Progressive {Supervision} for {Node} {Classification}},
	volume = {12457},
	isbn = {978-3-030-67657-5 978-3-030-67658-2},
	url = {https://link.springer.com/10.1007/978-3-030-67658-2_16},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	editor = {Hutter, Frank and Kersting, Kristian and Lijffijt, Jefrey and Valera, Isabel},
	year = {2021},
	doi = {10.1007/978-3-030-67658-2_16},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {266--281},
}

@misc{bi_struedit_2024,
	title = {{StruEdit}: {Structured} {Outputs} {Enable} the {Fast} and {Accurate} {Knowledge} {Editing} for {Large} {Language} {Models}},
	shorttitle = {{StruEdit}},
	url = {http://arxiv.org/abs/2409.10132},
	doi = {10.48550/arXiv.2409.10132},
	abstract = {As the modern tool of choice for question answering, large language models (LLMs) are expected to deliver answers with up-to-date knowledge. To achieve such ideal question-answering systems, locating and then editing outdated knowledge in the natural language outputs is a general target of popular knowledge editing methods. However, this target is challenging, as both identifying which tokens to edit in the reasoning steps and ensuring the coherence of the revised reasoning chain are difficult tasks. We argue that these challenges stem from the unstructured nature of natural language outputs. To address the above challenges, we propose \${\textbackslash}textbf\{Stru\}\$ctural \${\textbackslash}textbf\{Edit\}\$ing (\${\textbackslash}textbf\{StruEdit\}\$), an improved baseline for knowledge editing. We first prompt LLMs to produce structured outputs consisting of reasoning triplets. Then, StruEdit removes any potentially outdated knowledge and efficiently refills the structured outputs with up-to-date information in a single step. Experimental results show that StruEdit consistently delivers the highest accuracy with lowest latency compared with other knowledge editing methods.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Gao, Hongcheng and Fang, Junfeng and Cheng, Xueqi},
	month = sep,
	year = {2024},
	note = {arXiv:2409.10132 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{meng_llm-_2024,
	title = {{LLM}-{A}*: {Large} {Language} {Model} {Enhanced} {Incremental} {Heuristic} {Search} on {Path} {Planning}},
	shorttitle = {{LLM}-{A}*},
	url = {http://arxiv.org/abs/2407.02511},
	doi = {10.48550/arXiv.2407.02511},
	abstract = {Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A* and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows. Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments. However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A* with the global reasoning capability of LLMs. This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios. By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Meng, Silin and Wang, Yiwei and Yang, Cheng-Fu and Peng, Nanyun and Chang, Kai-Wei},
	month = jun,
	year = {2024},
	note = {arXiv:2407.02511 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Robotics},
	annote = {Comment: Submitted to The 2024 Conference on Empirical Methods in Natural Language Processing},
}

@inproceedings{bi_lpnl_2024,
	title = {Lpnl: {Scalable} link prediction with large language models},
	shorttitle = {Lpnl},
	url = {https://aclanthology.org/2024.findings-acl.215/},
	urldate = {2024-12-29},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics} {ACL} 2024},
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Cheng, Xueqi},
	year = {2024},
	pages = {3615--3625},
}

@misc{bi_adaptive_2024,
	title = {Adaptive {Token} {Biaser}: {Knowledge} {Editing} via {Biasing} {Key} {Entities}},
	shorttitle = {Adaptive {Token} {Biaser}},
	url = {http://arxiv.org/abs/2406.12468},
	doi = {10.48550/arXiv.2406.12468},
	abstract = {The parametric knowledge memorized by large language models (LLMs) becomes outdated quickly. In-context editing (ICE) is currently the most effective method for updating the knowledge of LLMs. Recent advancements involve enhancing ICE by modifying the decoding strategy, obviating the need for altering internal model structures or adjusting external prompts. However, this enhancement operates across the entire sequence generation, encompassing a plethora of non-critical tokens. In this work, we introduce \${\textbackslash}textbf\{A\}\$daptive \${\textbackslash}textbf\{T\}\$oken \${\textbackslash}textbf\{Bias\}\$er (\${\textbackslash}textbf\{ATBias\}\$), a new decoding technique designed to enhance ICE. It focuses on the tokens that are mostly related to knowledge during decoding, biasing their logits by matching key entities related to new and parametric knowledge. Experimental results show that ATBias significantly enhances ICE performance, achieving up to a 32.3\% improvement over state-of-the-art ICE methods while incurring only half the latency. ATBias not only improves the knowledge editing capabilities of ICE but can also be widely applied to LLMs with negligible cost.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Gao, Hongcheng and Xu, Yilong and Cheng, Xueqi},
	month = jun,
	year = {2024},
	note = {arXiv:2406.12468 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{liu_unitst_2024,
	title = {{UniTST}: {Effectively} {Modeling} {Inter}-{Series} and {Intra}-{Series} {Dependencies} for {Multivariate} {Time} {Series} {Forecasting}},
	shorttitle = {{UniTST}},
	url = {http://arxiv.org/abs/2406.04975},
	doi = {10.48550/arXiv.2406.04975},
	abstract = {Transformer-based models have emerged as powerful tools for multivariate time series forecasting (MTSF). However, existing Transformer models often fall short of capturing both intricate dependencies across variate and temporal dimensions in MTS data. Some recent models are proposed to separately capture variate and temporal dependencies through either two sequential or parallel attention mechanisms. However, these methods cannot directly and explicitly learn the intricate inter-series and intra-series dependencies. In this work, we first demonstrate that these dependencies are very important as they usually exist in real-world data. To directly model these dependencies, we propose a transformer-based model UniTST containing a unified attention mechanism on the flattened patch tokens. Additionally, we add a dispatcher module which reduces the complexity and makes the model feasible for a potentially large number of variates. Although our proposed model employs a simple architecture, it offers compelling performance as shown in our extensive experiments on several datasets for time series forecasting.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Liu, Juncheng and Liu, Chenghao and Woo, Gerald and Wang, Yiwei and Hooi, Bryan and Xiong, Caiming and Sahoo, Doyen},
	month = jun,
	year = {2024},
	note = {arXiv:2406.04975 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{wang_using_2017,
	address = {Singapore Singapore},
	title = {Using {Knowledge} {Graphs} to {Explain} {Entity} {Co}-occurrence in {Twitter}},
	isbn = {978-1-4503-4918-5},
	url = {https://dl.acm.org/doi/10.1145/3132847.3133161},
	doi = {10.1145/3132847.3133161},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 2017 {ACM} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Wang, Yiwei and Carman, Mark James and Li, Yuan-Fang},
	month = nov,
	year = {2017},
	pages = {2351--2354},
}

@misc{bi_is_2024,
	title = {Is {Factuality} {Enhancement} a {Free} {Lunch} {For} {LLMs}? {Better} {Factuality} {Can} {Lead} to {Worse} {Context}-{Faithfulness}},
	shorttitle = {Is {Factuality} {Enhancement} a {Free} {Lunch} {For} {LLMs}?},
	url = {http://arxiv.org/abs/2404.00216},
	doi = {10.48550/arXiv.2404.00216},
	abstract = {As the modern tools of choice for text understanding and generation, large language models (LLMs) are expected to accurately output answers by leveraging the input context. This requires LLMs to possess both context-faithfulness and factual accuracy. Extensive efforts have been made to enable better outputs from LLMs by mitigating hallucinations through factuality enhancement methods. However, they also pose risks of hindering context-faithfulness, as factuality enhancement can lead LLMs to become overly confident in their parametric knowledge, causing them to overlook the relevant input context. In this work, we argue that current factuality enhancement methods can significantly undermine the context-faithfulness of LLMs. We first revisit the current factuality enhancement methods and evaluate their effectiveness in enhancing factual accuracy. Next, we evaluate their performance on knowledge editing tasks to assess the potential impact on context-faithfulness. The experimental results reveal that while these methods may yield inconsistent improvements in factual accuracy, they also cause a more severe decline in context-faithfulness, with the largest decrease reaching a striking 69.7{\textbackslash}\%. To explain these declines, we analyze the hidden states and logit distributions for the tokens representing new knowledge and parametric knowledge respectively, highlighting the limitations of current approaches. Our finding highlights the complex trade-offs inherent in enhancing LLMs. Therefore, we recommend that more research on LLMs' factuality enhancement make efforts to reduce the sacrifice of context-faithfulness.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Fang, Junfeng and Gao, Hongcheng and Ni, Shiyu and Cheng, Xueqi},
	month = oct,
	year = {2024},
	note = {arXiv:2404.00216 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{wang_structure-aware_2021,
	title = {Structure-{Aware} {Label} {Smoothing} for {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2112.00499},
	doi = {10.48550/arXiv.2112.00499},
	abstract = {Representing a label distribution as a one-hot vector is a common practice in training node classification models. However, the one-hot representation may not adequately reflect the semantic characteristics of a node in different classes, as some nodes may be semantically close to their neighbors in other classes. It would cause over-confidence since the models are encouraged to assign full probabilities when classifying every node. While training models with label smoothing can ease this problem to some degree, it still fails to capture the nodes' semantic characteristics implied by the graph structures. In this work, we propose a novel SALS ({\textbackslash}textit\{Structure-Aware Label Smoothing\}) method as an enhancement component to popular node classification models. SALS leverages the graph structures to capture the semantic correlations between the connected nodes and generate the structure-aware label distribution to replace the original one-hot label vectors, thus improving the node classification performance without inference costs. Extensive experiments on seven node classification benchmark datasets reveal the effectiveness of our SALS on improving both transductive and inductive node classification. Empirical results show that SALS is superior to the label smoothing method and enhances the node classification models to outperform the baseline methods.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Yiwei and Cai, Yujun and Liang, Yuxuan and Wang, Wei and Ding, Henghui and Chen, Muhao and Tang, Jing and Hooi, Bryan},
	month = dec,
	year = {2021},
	note = {arXiv:2112.00499 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@misc{wang_con-recall_2024,
	title = {Con-{ReCall}: {Detecting} {Pre}-training {Data} in {LLMs} via {Contrastive} {Decoding}},
	shorttitle = {Con-{ReCall}},
	url = {http://arxiv.org/abs/2409.03363},
	doi = {10.48550/arXiv.2409.03363},
	abstract = {The training data in large language models is key to their success, but it also presents privacy and security risks, as it may contain sensitive information. Detecting pre-training data is crucial for mitigating these concerns. Existing methods typically analyze target text in isolation or solely with non-member contexts, overlooking potential insights from simultaneously considering both member and non-member contexts. While previous work suggested that member contexts provide little information due to the minor distributional shift they induce, our analysis reveals that these subtle shifts can be effectively leveraged when contrasted with non-member contexts. In this paper, we propose Con-ReCall, a novel approach that leverages the asymmetric distributional shifts induced by member and non-member contexts through contrastive decoding, amplifying subtle differences to enhance membership inference. Extensive empirical evaluations demonstrate that Con-ReCall achieves state-of-the-art performance on the WikiMIA benchmark and is robust against various text manipulation techniques.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Wang, Cheng and Wang, Yiwei and Hooi, Bryan and Cai, Yujun and Peng, Nanyun and Chang, Kai-Wei},
	month = sep,
	year = {2024},
	note = {arXiv:2409.03363 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{liang_revisiting_2020,
	title = {Revisiting convolutional neural networks for urban flow analytics},
	url = {https://scholarbank.nus.edu.sg/handle/10635/169470},
	urldate = {2024-12-29},
	author = {Liang, Yuxuan and Ouyang, Kun and Wang, Yiwei and Rosenblum, David Samuel},
	year = {2020},
}

@misc{yang_optibench_2024,
	title = {{OptiBench} {Meets} {ReSocratic}: {Measure} and {Improve} {LLMs} for {Optimization} {Modeling}},
	shorttitle = {{OptiBench} {Meets} {ReSocratic}},
	url = {http://arxiv.org/abs/2407.09887},
	doi = {10.48550/arXiv.2407.09887},
	abstract = {Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose OptiBench, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. OptiBench contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, {\textbackslash}ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ReSocratic-29k dataset. We further conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. Experimental results show that ReSocratic-29k significantly improves the performance of open-source models.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Yang, Zhicheng and Wang, Yiwei and Huang, Yinya and Guo, Zhijiang and Shi, Wei and Han, Xiongwei and Feng, Liang and Song, Linqi and Liang, Xiaodan and Tang, Jing},
	month = oct,
	year = {2024},
	note = {arXiv:2407.09887 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@misc{mei_not_2024,
	title = {"{Not} {Aligned}" is {Not} "{Malicious}": {Being} {Careful} about {Hallucinations} of {Large} {Language} {Models}' {Jailbreak}},
	shorttitle = {"{Not} {Aligned}" is {Not} "{Malicious}"},
	url = {http://arxiv.org/abs/2406.11668},
	doi = {10.48550/arXiv.2406.11668},
	abstract = {"Jailbreak" is a major safety concern of Large Language Models (LLMs), which occurs when malicious prompts lead LLMs to produce harmful outputs, raising issues about the reliability and safety of LLMs. Therefore, an effective evaluation of jailbreaks is very crucial to develop its mitigation strategies. However, our research reveals that many jailbreaks identified by current evaluations may actually be hallucinations-erroneous outputs that are mistaken for genuine safety breaches. This finding suggests that some perceived vulnerabilities might not represent actual threats, indicating a need for more precise red teaming benchmarks. To address this problem, we propose the \${\textbackslash}textbf\{B\}\$enchmark for reli\${\textbackslash}textbf\{AB\}\$ilit\${\textbackslash}textbf\{Y\}\$ and jail\${\textbackslash}textbf\{B\}\$reak ha\${\textbackslash}textbf\{L\}\$l\${\textbackslash}textbf\{U\}\$cination \${\textbackslash}textbf\{E\}\$valuation (BabyBLUE). BabyBLUE introduces a specialized validation framework including various evaluators to enhance existing jailbreak benchmarks, ensuring outputs are useful malicious instructions. Additionally, BabyBLUE presents a new dataset as an augmentation to the existing red teaming benchmarks, specifically addressing hallucinations in jailbreaks, aiming to evaluate the true potential of jailbroken LLM outputs to cause harm to human society.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Mei, Lingrui and Liu, Shenghua and Wang, Yiwei and Bi, Baolong and Mao, Jiayi and Cheng, Xueqi},
	month = jun,
	year = {2024},
	note = {arXiv:2406.11668 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{mei_slang_2024,
	title = {{SLANG}: {New} {Concept} {Comprehension} of {Large} {Language} {Models}},
	shorttitle = {{SLANG}},
	url = {http://arxiv.org/abs/2401.12585},
	doi = {10.48550/arXiv.2401.12585},
	abstract = {The dynamic nature of language, particularly evident in the realm of slang and memes on the Internet, poses serious challenges to the adaptability of large language models (LLMs). Traditionally anchored to static datasets, these models often struggle to keep up with the rapid linguistic evolution characteristic of online communities. This research aims to bridge this gap by enhancing LLMs' comprehension of the evolving new concepts on the Internet, without the high cost of continual retraining. In pursuit of this goal, we introduce \${\textbackslash}textbf\{SLANG\}\$, a benchmark designed to autonomously integrate novel data and assess LLMs' ability to comprehend emerging concepts, alongside \${\textbackslash}textbf\{FOCUS\}\$, an approach uses causal inference to enhance LLMs to understand new phrases and their colloquial context. Our benchmark and approach involves understanding real-world instances of linguistic shifts, serving as contextual beacons, to form more precise and contextually relevant connections between newly emerging expressions and their meanings. The empirical analysis shows that our causal inference-based approach outperforms the baseline methods in terms of precision and relevance in the comprehension of Internet slang and memes.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Mei, Lingrui and Liu, Shenghua and Wang, Yiwei and Bi, Baolong and Cheng, Xueqi},
	month = nov,
	year = {2024},
	note = {arXiv:2401.12585 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2024 Main},
}

@article{ge_graph_2024,
	title = {Graph {Descriptive} {Order} {Improves} {Reasoning} with {Large} {Language} {Model}},
	url = {https://openreview.net/forum?id=UkKIRGd42P},
	urldate = {2024-12-29},
	journal = {CoRR},
	author = {Ge, Yuyao and Liu, Shenghua and Feng, Wenjie and Mei, Lingrui and Chen, Lizhe and Cheng, Xueqi},
	year = {2024},
}

@inproceedings{wang_time-aware_2022,
	title = {Time-{Aware} {Neighbor} {Sampling} on {Temporal} {Graphs}},
	url = {https://ieeexplore.ieee.org/abstract/document/9892942/},
	urldate = {2024-12-29},
	booktitle = {2022 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Wang, Yiwei and Cai, Yujun and Liang, Yuxuan and Ding, Henghui and Wang, Changhu and Hooi, Bryan},
	year = {2022},
	pages = {1--8},
}

@article{wang_vulnerability_2024,
	title = {Vulnerability of {Large} {Language} {Models} to {Output} {Prefix} {Jailbreaks}: {Impact} of {Positions} on {Safety}},
	shorttitle = {Vulnerability of {Large} {Language} {Models} to {Output} {Prefix} {Jailbreaks}},
	url = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.173161123.33560859},
	urldate = {2024-12-29},
	journal = {Authorea Preprints},
	author = {Wang, Yiwei and Chen, Muhao and Peng, Nanyun and Chang, Kai-Wei},
	year = {2024},
	note = {Publisher: Authorea},
}

@misc{li_vulnerability_2024,
	title = {Vulnerability of {LLMs} to {Vertically} {Aligned} {Text} {Manipulations}},
	url = {http://arxiv.org/abs/2410.20016},
	doi = {10.48550/arXiv.2410.20016},
	abstract = {Text classification involves categorizing a given text, such as determining its sentiment or identifying harmful content. With the advancement of large language models (LLMs), these models have become highly effective at performing text classification tasks. However, they still show vulnerabilities to variations in text formatting. Recent research demonstrates that modifying input formats, such as vertically aligning words for encoder-based models, can substantially lower accuracy in text classification tasks. While easily understood by humans, these inputs can significantly mislead models, posing a potential risk of bypassing detection in real-world scenarios involving harmful or sensitive information. With the expanding application of LLMs, a crucial question arises: Do decoder-based LLMs exhibit similar vulnerabilities to vertically formatted text input? In this paper, we investigate the impact of vertical text input on the performance of various LLMs across multiple text classification datasets and analyze the underlying causes. Our findings are as follows: (i) Vertical text input significantly degrades the accuracy of LLMs in text classification tasks. (ii) Chain of Thought (CoT) reasoning does not help LLMs recognize vertical input or mitigate its vulnerability, but few-shot learning with careful analysis does. (iii) We explore the underlying cause of the vulnerability by analyzing the inherent issues in tokenization and attention matrices.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Li, Zhecheng and Wang, Yiwei and Hooi, Bryan and Cai, Yujun and Xiong, Zhen and Peng, Nanyun and Chang, Kai-wei},
	month = oct,
	year = {2024},
	note = {arXiv:2410.20016 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{bi_is_2024-1,
	title = {Is {Factuality} {Enhancement} a {Free} {Lunch} {For} {LLMs}? {Better} {Factuality} {Can} {Lead} to {Worse} {Context}-{Faithfulness}},
	shorttitle = {Is {Factuality} {Enhancement} a {Free} {Lunch} {For} {LLMs}?},
	url = {https://www.authorea.com/doi/full/10.36227/techrxiv.173160875.51599596},
	urldate = {2024-12-29},
	journal = {Authorea Preprints},
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Fang, Junfeng and Gao, Hongcheng and Ni, Shiyu and Cheng, Xueqi},
	year = {2024},
	note = {Publisher: Authorea},
}

@misc{li_think_2024,
	title = {Think {Carefully} and {Check} {Again}! {Meta}-{Generation} {Unlocking} {LLMs} for {Low}-{Resource} {Cross}-{Lingual} {Summarization}},
	url = {http://arxiv.org/abs/2410.20021},
	doi = {10.48550/arXiv.2410.20021},
	abstract = {Cross-lingual summarization (CLS) aims to generate a summary for the source text in a different target language. Currently, instruction-tuned large language models (LLMs) excel at various English tasks. However, unlike languages such as English, Chinese or Spanish, for those relatively low-resource languages with limited usage or data, recent studies have shown that LLMs' performance on CLS tasks remains unsatisfactory even with few-shot settings. This raises the question: Are LLMs capable of handling cross-lingual summarization tasks for low-resource languages? To resolve this question, we fully explore the potential of large language models on cross-lingual summarization task for low-resource languages through our four-step zero-shot method: Summarization, Improvement, Translation and Refinement (SITR) with correspondingly designed prompts. We test our proposed method with multiple LLMs on two well-known cross-lingual summarization datasets with various low-resource target languages. The results show that: i) GPT-3.5 and GPT-4 significantly and consistently outperform other baselines when using our zero-shot SITR methods. ii) By employing our proposed method, we unlock the potential of LLMs, enabling them to effectively handle cross-lingual summarization tasks for relatively low-resource languages.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Li, Zhecheng and Wang, Yiwei and Hooi, Bryan and Cai, Yujun and Cheung, Naifan and Peng, Nanyun and Chang, Kai-wei},
	month = oct,
	year = {2024},
	note = {arXiv:2410.20021 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{li_control_2024,
	title = {Control {Large} {Language} {Models} via {Divide} and {Conquer}},
	url = {http://arxiv.org/abs/2410.04628},
	doi = {10.48550/arXiv.2410.04628},
	abstract = {This paper investigates controllable generation for large language models (LLMs) with prompt-based control, focusing on Lexically Constrained Generation (LCG). We systematically evaluate the performance of LLMs on satisfying lexical constraints with prompt-based control, as well as their efficacy in downstream applications. We conclude that LLMs face significant challenges in consistently satisfying lexical constraints with prompt-based control. We identified three key limitations of LLMs for LCG, including (1) position bias, where LLMs tend to satisfy constraints that appear in specific positions within the input; (2) low responsiveness to decoding parameters, which render minimal impact on control of LLMs; and (3) struggle with handling the inherent complexity of certain constraints (e.g., compound words). To address these issues, we introduce a Divide and Conquer Generation strategy, effective for both white-box and black-box LLMs, to enhance LLMs performance in LCG tasks, which demonstrates over 90\% improvement on success rate in the most challenging LCG task. Our analysis provides valuable insights into the performance of LLMs in LCG with prompt-based control, and our proposed strategy offers a pathway to more sophisticated and customized text generation applications.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Li, Bingxuan and Wang, Yiwei and Meng, Tao and Chang, Kai-Wei and Peng, Nanyun},
	month = oct,
	year = {2024},
	note = {arXiv:2410.04628 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2024},
}

@misc{mei_hiddenguard_2024,
	title = {{HiddenGuard}: {Fine}-{Grained} {Safe} {Generation} with {Specialized} {Representation} {Router}},
	shorttitle = {{HiddenGuard}},
	url = {http://arxiv.org/abs/2410.02684},
	doi = {10.48550/arXiv.2410.02684},
	abstract = {As Large Language Models (LLMs) grow increasingly powerful, ensuring their safety and alignment with human values remains a critical challenge. Ideally, LLMs should provide informative responses while avoiding the disclosure of harmful or sensitive information. However, current alignment approaches, which rely heavily on refusal strategies, such as training models to completely reject harmful prompts or applying coarse filters are limited by their binary nature. These methods either fully deny access to information or grant it without sufficient nuance, leading to overly cautious responses or failures to detect subtle harmful content. For example, LLMs may refuse to provide basic, public information about medication due to misuse concerns. Moreover, these refusal-based methods struggle to handle mixed-content scenarios and lack the ability to adapt to context-dependent sensitivities, which can result in over-censorship of benign content. To overcome these challenges, we introduce HiddenGuard, a novel framework for fine-grained, safe generation in LLMs. HiddenGuard incorporates Prism (rePresentation Router for In-Stream Moderation), which operates alongside the LLM to enable real-time, token-level detection and redaction of harmful content by leveraging intermediate hidden states. This fine-grained approach allows for more nuanced, context-aware moderation, enabling the model to generate informative responses while selectively redacting or replacing sensitive information, rather than outright refusal. We also contribute a comprehensive dataset with token-level fine-grained annotations of potentially harmful information across diverse contexts. Our experiments demonstrate that HiddenGuard achieves over 90\% in F1 score for detecting and redacting harmful content while preserving the overall utility and informativeness of the model's responses.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Mei, Lingrui and Liu, Shenghua and Wang, Yiwei and Bi, Baolong and Yuan, Ruibin and Cheng, Xueqi},
	month = oct,
	year = {2024},
	note = {arXiv:2410.02684 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{zhong_mquake-remastered_2024,
	title = {{MQuAKE}-{Remastered}: {Multi}-{Hop} {Knowledge} {Editing} {Can} {Only} {Be} {Advanced} {With} {Reliable} {Evaluations}},
	shorttitle = {{MQuAKE}-{Remastered}},
	url = {https://openreview.net/forum?id=iTUlYblV0K},
	urldate = {2024-12-29},
	author = {Zhong, Shaochen and Lu, Yifan and Shao, Lize and Bhushanam, Bhargav and Du, Xiaocong and Feng, Louis and Wan, Yixin and Shi, Yucheng and Zha, Daochen and Wang, Yiwei},
	year = {2024},
}

@article{forecasting_unitst_nodate,
	title = {{UniTST}: {Effectively} {Modeling} {Inter}-{Series} and {Intra}-{Series} {Dependencies} for {Multivariate} {Time} {Series} {Forecasting}},
	shorttitle = {{UniTST}},
	url = {https://openreview.net/forum?id=cuFnNExmdq},
	urldate = {2024-12-29},
	author = {FORECASTING, TIME SERIES},
}
